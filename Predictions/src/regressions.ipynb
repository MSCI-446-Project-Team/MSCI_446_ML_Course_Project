{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the merged dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../Final_table.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.iloc[:, 1:].corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataframe into test and training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_var = data.iloc[:,[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,25,26,27,28]]\n",
    "target_var = data['DPL_historical_da']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature_var, target_var, test_size=0.2, random_state=156)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "model_fr = SelectKBest(score_func=f_regression, k=5)\n",
    "\n",
    "data_new_fr = model_fr.fit(X_train, y_train)\n",
    "\n",
    "print(\"the F-test method computes the F-statistic for each feature, measuring the linear dependency between the feature and the target\")\n",
    "print(\"f_regression: \", data_new_fr.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing the details between variane and linear dependancy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fc = pd.DataFrame({'column':X_train.columns, 'p':data_new_fc.pvalues_, 'score':data_new_fc.scores_})\n",
    "df_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fr = pd.DataFrame({'column':X_train.columns, 'p':data_new_fr.pvalues_, 'score':data_new_fr.scores_})\n",
    "df_fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model_la = Lasso(alpha=0.1)\n",
    "\n",
    "model_la.fit(X_train, y_train)\n",
    "\n",
    "predict = model_la.predict(X_test)\n",
    "print('r2 ', r2_score(y_test, predict))\n",
    "print('mse: ',metrics.mean_squared_error(predict, y_test))\n",
    "print('mape: ',metrics.mean_absolute_percentage_error(predict, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = range(len(X_test))\n",
    "\n",
    "plt.scatter(index, predict, color='blue', label='Predicted')\n",
    "plt.scatter(index, y_test, color='red', label='True')\n",
    "plt.title('Lasso True Values vs. Predicted Values')\n",
    "plt.xlabel('Index of X_test')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axs[0].hist(predict, bins=10, color='blue', alpha=0.7)\n",
    "axs[0].set_title('Lasso Histogram of Predicted Values')\n",
    "axs[0].set_xlabel('Predicted Values')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "axs[1].hist(y_test, bins=10, color='red', alpha=0.7)\n",
    "axs[1].set_title('Lasso Histogram of test Values')\n",
    "axs[1].set_xlabel('test')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "axs[2].hist(y_train, bins=10, color='red', alpha=0.7)\n",
    "axs[2].set_title('Lasso Histogram of train Values')\n",
    "axs[2].set_xlabel('train')\n",
    "axs[2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model_rid = Ridge(alpha=0.1)\n",
    "model_rid.fit(X_train, y_train)\n",
    "predict_rid = model_rid.predict(X_test)\n",
    "print('r2 ', r2_score(y_test, predict_rid))\n",
    "print('mse: ',metrics.mean_squared_error(predict_rid, y_test))\n",
    "print('mape: ',metrics.mean_absolute_percentage_error(predict_rid, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = range(len(X_test))\n",
    "\n",
    "plt.scatter(index, predict_rid, color='blue', label='Predicted')\n",
    "plt.scatter(index, y_test, color='red', label='True')\n",
    "plt.title('RidgeTrue Values vs. Predicted Values')\n",
    "plt.xlabel('Index of X_test')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "axs[0].hist(predict_rid, bins=10, color='blue', alpha=0.7)\n",
    "axs[0].set_title('Ridge Histogram of Predicted Values')\n",
    "axs[0].set_xlabel('Predicted Values')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "\n",
    "axs[1].hist(y_test, bins=10, color='red', alpha=0.7)\n",
    "axs[1].set_title('Lasso Histogram of test Values')\n",
    "axs[1].set_xlabel('test')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "\n",
    "axs[2].hist(y_train, bins=10, color='red', alpha=0.7)\n",
    "axs[2].set_title('Lasso Histogram of train Values')\n",
    "axs[2].set_xlabel('train')\n",
    "axs[2].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression()\n",
    "lm_sub = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "lm_sub.fit(X_train.iloc[:,[13,18,21,22,26]], y_train)\n",
    "\n",
    "predict_lm = lm.predict(X_test)\n",
    "predict_lm_sub = lm_sub.predict(X_test.iloc[:,[13,18,21,22,26]])\n",
    "\n",
    "print('r2 ', r2_score(y_test, predict_lm))\n",
    "print('mse: ', metrics.mean_squared_error(y_train, lm.predict(X_train)))\n",
    "print('r2 sub ', r2_score(y_test, predict_lm_sub))\n",
    "print('mse sub: ', metrics.mean_squared_error(y_train, lm_sub.predict(X_train.iloc[:,[13,18,21,22,26]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(5, 1, figsize=(8, 20))\n",
    "\n",
    "sns.regplot(x=X_train['APS_forecast'], y=y_train, order=1, ci=None, scatter_kws={'color':'r', 's':9}, ax=axs[0])\n",
    "axs[0].set_title('Regression Plot for APS_forecast')\n",
    "axs[0].set_xlabel('APS_forecast')\n",
    "axs[0].set_ylabel('y_train')\n",
    "\n",
    "sns.regplot(x=X_train['DOM_forecast'], y=y_train, order=1, ci=None, scatter_kws={'color':'g', 's':9}, ax=axs[1])\n",
    "axs[1].set_title('Regression Plot for DOM_forecast')\n",
    "axs[1].set_xlabel('DOM_forecast')\n",
    "axs[1].set_ylabel('y_train')\n",
    "\n",
    "sns.regplot(x=X_train['MIDATL_forecast'], y=y_train, order=1, ci=None, scatter_kws={'color':'purple', 's':9}, ax=axs[2])\n",
    "axs[2].set_title('Regression Plot for MIDATL_forecast')\n",
    "axs[2].set_xlabel('MIDATL_forecast')\n",
    "axs[2].set_ylabel('y_train')\n",
    "\n",
    "sns.regplot(x=X_train['RTO_forecast'], y=y_train, order=1, ci=None, scatter_kws={'color':'y', 's':9}, ax=axs[3])\n",
    "axs[3].set_title('Regression Plot for RTO_forecast')\n",
    "axs[3].set_xlabel('RTO_forecast')\n",
    "axs[3].set_ylabel('y_train')\n",
    "\n",
    "sns.regplot(x=X_train['Henry Hub Natural Gas Spot Price (Dollars per Million Btu)'], y=y_train, order=1, ci=None, scatter_kws={'color':'orange', 's':9}, ax=axs[4])\n",
    "axs[4].set_title('Regression Plot for Henry Hub Price')\n",
    "axs[4].set_xlabel('Henry Hub Price')\n",
    "axs[4].set_ylabel('y_train')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from mlxtend.evaluate import bias_variance_decomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse, bias,var = bias_variance_decomp(lm_sub,\n",
    "                                     X_train.iloc[:,[13,18,21,22,26]].to_numpy(), y_train.to_numpy(), X_test.iloc[:,[13,18,21,22,26]].to_numpy(), y_test.to_numpy(), \n",
    "                                     loss='mse', num_rounds=200, random_seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSEs   = []\n",
    "Biases = []\n",
    "Vars   = []\n",
    "poly_models = []\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "for i in range(1,8):\n",
    "    poly         = PolynomialFeatures (degree=i, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train.iloc[:,[13,18,21,22,26]])\n",
    "    X_test_poly  = poly.fit_transform(X_test.iloc[:,[13,18,21,22,26]])\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "\n",
    "    poly_models.append(model)\n",
    "    \n",
    "    mse, bias, var = bias_variance_decomp(model,\n",
    "                                           X_train_poly, y_train.to_numpy(), X_test_poly, y_test.to_numpy(),\n",
    "                                           loss='mse', num_rounds=200, random_seed=100)\n",
    "\n",
    "    MSEs.append(mse)\n",
    "    Biases.append(bias)\n",
    "    Vars.append(var)\n",
    "    \n",
    "\n",
    "    cv_results = cross_validate(model, X_train_poly, y_train, cv=10, scoring='neg_mean_absolute_error')\n",
    "    mse_avg = -cv_results['test_score'].mean()\n",
    "\n",
    "    y_pred = model.predict(X_test_poly)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print('Degree: %s, MSE: %s, Bias: %s, Var: %s, Cross-Validation: %s, R2_score %s ' %(i,mse.round(2),bias.round(2),var.round(2),mse_avg.round(2),r2.round(2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_values = range(1, len(MSEs) + 1) \n",
    "plt.plot(x_values, MSEs, label='MSE')\n",
    "plt.plot(x_values, Biases, label='Bias')\n",
    "plt.plot(x_values, Vars, label='Var')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Values')\n",
    "plt.title('Plot of Three Arrays')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_la = cross_validate(model_la, feature_var, target_var, cv=10, scoring='neg_mean_absolute_error')\n",
    "cv_results_rid = cross_validate(model_rid, feature_var, target_var, cv=10, scoring='neg_mean_absolute_error')\n",
    "cv_results_lm_sub = cross_validate(lm_sub, feature_var, target_var, cv=10, scoring='neg_mean_absolute_error')\n",
    "cv_results_lm = cross_validate(lm, feature_var, target_var, cv=10, scoring='neg_mean_absolute_error')\n",
    "\n",
    "mse_avg_la = -cv_results_la['test_score'].mean()\n",
    "mse_avg_rid = -cv_results_rid['test_score'].mean()\n",
    "mse_avg_lm_sub = -cv_results_lm_sub['test_score'].mean()\n",
    "mse_avg_lm = -cv_results_lm['test_score'].mean()\n",
    "\n",
    "y_pred_la = model.predict(X_test_poly)\n",
    "y_pred_rid = model.predict(X_test_poly)\n",
    "y_pred_lm_sub = model.predict(X_test_poly)\n",
    "y_pred_lm = model.predict(X_test_poly)\n",
    "\n",
    "r2_la = r2_score(y_test, y_pred_la)\n",
    "r2_rid = r2_score(y_test, y_pred_rid)\n",
    "r2_lm_sub = r2_score(y_test, y_pred_lm_sub)\n",
    "r2_lm = r2_score(y_test, y_pred_lm)\n",
    "\n",
    "print('Lasso MSE (10-Fold CV): ', mse_avg_la)\n",
    "print('Ridge MSE (10-Fold CV): ', mse_avg_rid)\n",
    "print('Linear Subset MSE (10-Fold CV): ', mse_avg_lm_sub)\n",
    "print('Linear MSE (10-Fold CV): ', mse_avg_lm)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
