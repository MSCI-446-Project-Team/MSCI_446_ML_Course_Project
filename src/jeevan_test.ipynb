{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "load_dotenv()\n",
    "cluster_uri = os.environ.get(\"MONGODB_URI\")\n",
    "client = MongoClient(cluster_uri)\n",
    "db = client[\"MSCI446_DB\"]\n",
    "collection = db[\"Load_Forecast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  forecast_hour_beginning_ept forecast_area  forecast_load_mw\n",
      "0        1/1/2024 12:00:00 AM           AEP             14145\n",
      "1         1/1/2024 1:00:00 AM           AEP             13908\n",
      "2         1/1/2024 2:00:00 AM           AEP             13765\n",
      "3         1/1/2024 3:00:00 AM           AEP             13788\n",
      "4         1/1/2024 4:00:00 AM           AEP             13862\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "documents = list(collection.find())\n",
    "\n",
    "# Convert the list of documents into a DataFrame\n",
    "df = pd.DataFrame(documents)\n",
    "\n",
    "# Optionally, you can drop the '_id' column if you don't need it\n",
    "df.drop('_id', axis=1, inplace=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  datetime_beginning_ept    area  solar_generation_mw\n",
      "0  2/28/2024 11:00:00 PM  MIDATL                  0.0\n",
      "1  2/28/2024 11:00:00 PM   OTHER                  0.0\n",
      "2  2/28/2024 11:00:00 PM     RFC                  0.0\n",
      "3  2/28/2024 11:00:00 PM     RTO                  0.0\n",
      "4  2/28/2024 11:00:00 PM   SOUTH                  0.0\n",
      "   datetime_beginning_ept    area  wind_generation_mw\n",
      "0  12/31/2020 11:00:00 PM  MIDATL             112.120\n",
      "1  12/31/2020 11:00:00 PM   SOUTH             156.846\n",
      "2  12/31/2020 11:00:00 PM    WEST            2130.528\n",
      "3  12/31/2020 11:00:00 PM     RTO            2399.494\n",
      "4  12/31/2020 11:00:00 PM     RFC            2242.648\n"
     ]
    }
   ],
   "source": [
    "collection_solar = db[\"Solar_Forecast\"]\n",
    "collection_wind = db[\"Wind_Forecast\"]\n",
    "documents_solar = list(collection_solar.find())\n",
    "documents_wind = list(collection_wind.find())\n",
    "df_solar = pd.DataFrame(documents_solar)\n",
    "df_wind = pd.DataFrame(documents_wind)\n",
    "df_solar.drop('_id', axis=1, inplace=True)\n",
    "df_wind.drop('_id', axis=1, inplace=True)\n",
    "\n",
    "print(df_solar.head())\n",
    "print(df_wind.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique areas in Solar Forecast table: ['MIDATL' 'OTHER' 'RFC' 'RTO' 'SOUTH' 'WEST']\n",
      "Unique areas in Wind Forecast table: ['MIDATL' 'SOUTH' 'WEST' 'RTO' 'RFC' 'OTHER']\n"
     ]
    }
   ],
   "source": [
    "# Assuming df_solar and df_wind are already created and the '_id' column is dropped\n",
    "\n",
    "# Get unique area values from the Solar Forecast table\n",
    "unique_areas_solar = df_solar['area'].unique()\n",
    "\n",
    "# Get unique area values from the Wind Forecast table\n",
    "unique_areas_wind = df_wind['area'].unique()\n",
    "\n",
    "# Print the unique area values\n",
    "print(\"Unique areas in Solar Forecast table:\", unique_areas_solar)\n",
    "print(\"Unique areas in Wind Forecast table:\", unique_areas_wind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_wind.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wind_pivot = df_wind.pivot(index='datetime_beginning_ept', columns='area', values='wind_generation_mw')\n",
    "solar_pivot = df_solar.pivot(index='datetime_beginning_ept', columns='area', values='solar_generation_mw')\n",
    "\n",
    "# Merge the pivoted DataFrames along the dates\n",
    "merged_df = pd.merge(solar_pivot, wind_pivot, on='datetime_beginning_ept', suffixes=('_solar', '_wind'))\n",
    "# merged_df = pd.merge(merged_df, solar_pivot, on='date', suffixes=('_wind', '_solar'))\n",
    "\n",
    "# Reset index to make 'date' a column\n",
    "merged_df.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns\n",
    "# merged_df.columns = ['Date', 'North-values_load_forecast', 'South-values_load_forecast', 'East-values_load_forecast',\n",
    "                    #  'Upper-belt-values_wind', 'Lower-belt-values_wind', 'Mid-belt-values_wind', 'Side-belt-values_wind',\n",
    "                    #  'Atlantic-values_solar', 'Pacific-values_solar']\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_duplicates = df_wind[df_wind.duplicated(keep=False)]\n",
    "\n",
    "print(wind_duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_duplicates = df_solar[df_solar.duplicated(keep=False)]\n",
    "\n",
    "print(solar_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_drop_duplicates = df_solar.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows_with_other = df_solar[df_solar['area'] == 'OTHER']\n",
    "df_dropped_solar = df_solar.drop([16555, 69259])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_duplicates = df_dropped_solar[df_dropped_solar.duplicated(keep=False)]\n",
    "\n",
    "print(solar_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_pivot = df_wind.pivot_table(index='datetime_beginning_ept', columns='area', values='wind_generation_mw', aggfunc='mean')\n",
    "solar_pivot = df_solar.pivot_table(index='datetime_beginning_ept', columns='area', values='solar_generation_mw', aggfunc='mean')\n",
    "\n",
    "# Merge the pivoted DataFrames along the dates\n",
    "merged_df = pd.merge(solar_pivot, wind_pivot, on='datetime_beginning_ept', suffixes=('_solar', '_wind'))\n",
    "# merged_df = pd.merge(merged_df, solar_pivot, on='date', suffixes=('_wind', '_solar'))\n",
    "\n",
    "# Reset index to make 'date' a column\n",
    "merged_df.reset_index(inplace=True)\n",
    "\n",
    "# Rename the columns\n",
    "# merged_df.columns = ['Date', 'North-values_load_forecast', 'South-values_load_forecast', 'East-values_load_forecast',\n",
    "                    #  'Upper-belt-values_wind', 'Lower-belt-values_wind', 'Mid-belt-values_wind', 'Side-belt-values_wind',\n",
    "                    #  'Atlantic-values_solar', 'Pacific-values_solar']\n",
    "\n",
    "print(merged_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
